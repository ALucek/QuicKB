# Pipeline Stage Control
pipeline:
  from_stage: "CHUNK"    # Options: CHUNK, GENERATE, TRAIN, UPLOAD
  to_stage: "UPLOAD"

# Path to Knowledgebase Directory
path_to_knowledgebase: "./testing/knowledgebase"

# Chunking
chunker: "RecursiveTokenChunker" 
chunker_arguments:
  chunk_size: 400
  chunk_overlap: 0
  separators: ["\n\n", "\n", ".", "?", "!", " ", ""]
  keep_separator: true
  is_separator_regex: false
  length_function: "character"
output_path: "./output/knowledgebase-quickb.json" # Chunked Output Path

# Synthetic Dataset Generation
question_output_path: "./output/train_data.json" # Generated Questions Output Path
question_model: "gpt-4o-mini"
question_max_workers: 20
deduplication:
  enabled: true
  similarity_threshold: 0.85

# Hugging Face Hub info
hub_username: "AdamLucek"
hub_token: null  # or rely on HF_TOKEN environment variable
hub_private: false

# Embedding training config
training:
  model_id: "nomic-ai/modernbert-embed-base"
  output_dir: "./output/modernbert_mtl"
  epochs: 4
  learning_rate: 2.0e-5
  matryoshka_dimensions: [768, 512, 256, 128, 64]
  batch_size: 32
  gradient_accumulation_steps: 16
  metric_for_best_model: "eval_dim_128_cosine_ndcg@10"
  push_to_hub: true
  hub_model_id: "AdamLucek/modernbert-embed-quickb"