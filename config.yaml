# Pipeline Stage Control
pipeline:
  from_stage: "GENERATE"    # Options: CHUNK, GENERATE, TRAIN
  to_stage: "GENERATE"

# Path to Knowledgebase Directory
path_to_knowledgebase: "./testing/knowledgebase"

# Base HF Hub credentials
hub_username: "AdamLucek"
hub_token: null  # or rely on HF_TOKEN environment variable

# ========== Chunking Config ==========
chunker_config:
  output_path: "./output/knowledgebase-quickb.json"
  
  # Chunker Arguments
  chunker: "RecursiveTokenChunker"
  chunker_arguments:
    chunk_size: 400
    chunk_overlap: 0
    separators: ["\n\n", "\n", ".", "?", "!", " ", ""]
    keep_separator: true
    is_separator_regex: false
    length_type: "character"
  
  upload_config:
    push_to_hub: true
    hub_private: false
    hub_dataset_id: "AdamLucek/quickb-hub-testing"

# ========== Question Generation ==========
question_generation:
  output_path: "./output/train_data.json"

  # LLM & Embedding Model Config
  litellm_config:
    model: "openai/gpt-4o-mini"
    model_api_base: null
    embedding_model: "text-embedding-3-large"
    embedding_api_base: null

  input_dataset_config:
    dataset_source: "hub" # Options: "local", "hub" - Default to local
    hub_dataset_id: "AdamLucek/quickb-hub-testing"
    # local_knowledgebase_path: ./output/knowledgebase-quickb.json # ADD THIS LINE - Explicit path for KB

  # API Limits
  max_workers: 100
  llm_calls_per_minute: null
  embedding_calls_per_minute: null

  # Deduplication Config
  deduplication_enabled: true
  dedup_embedding_batch_size: 2048
  similarity_threshold: 0.85

  upload_config:
    push_to_hub: true
    hub_private: false
    hub_dataset_id: "AdamLucek/quickb-hub-testing"

# ========== Training config ==========
training:
  # Main Model Selection & MRL Loss Setup
  model_settings:
    model_id: "nomic-ai/modernbert-embed-base"
    matryoshka_dimensions: [768, 512, 256, 128, 64]
    metric_for_best_model: "eval_dim_128_cosine_ndcg@10"
    max_seq_length: 1024
    trust_remote_code: false

  train_dataset_config:
    dataset_source: "hub" # Options: "local", "hub" - Default to local
    hub_dataset_id: "AdamLucek/quickb-hub-test-4"      # Required if dataset_source: "hub" - Leave null for local
    local_train_dataset_path: null 
    local_knowledgebase_path: "./output/knowledgebase-quickb.json"

  # Trainer Arguments
  training_arguments:
    output_path: "./output/modernbert_quickb"
    epochs: 4
    learning_rate: 2.0e-5
    batch_size: 32
    gradient_accumulation_steps: 16
    warmup_ratio: 0.1
    lr_scheduler_type: "cosine"
    optim: "adamw_torch_fused"
    tf32: true
    bf16: true
    batch_sampler: "no_duplicates"
    eval_strategy: "epoch"
    save_strategy: "epoch"
    logging_steps: 10
    save_total_limit: 3
    load_best_model_at_end: true
    report_to: "none"

  upload_config:
    push_to_hub: false
    hub_private: false
    hub_model_id: "AdamLucek/modernbert-embed-quickb"